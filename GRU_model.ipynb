{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.utils import resample\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.metrics import categorical_accuracy\n",
    "from keras import layers, optimizers\n",
    "from keras.layers import Input, GRU, Dense,LSTM, Dropout, Embedding\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras import regularizers\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import one_hot,Tokenizer\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import pretrained embedding models (automotive industry context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec_CRs = gensim.models.Word2Vec.load(\"w2v_CRs\")\n",
    "fasttext_CRs = FastText.load(\"fasttext_CRs.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_pickle(\"trainset-Copy1.txt\")\n",
    "test_data = pd.read_pickle(\"test_set\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Upsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_i = train_data[train_data.label == \"I\"]\n",
    "df_g = train_data[train_data.label == \"G\"]\n",
    "df_e = train_data[train_data.label == \"E\"]\n",
    "df_c = train_data[train_data.label == \"C\"]\n",
    "df_d = train_data[train_data.label == \"D\"]\n",
    "df_rest = train_data\n",
    "df_rest = df_rest [df_rest.label != 'I']\n",
    "df_rest = df_rest[df_rest.label != 'G']\n",
    "df_rest= df_rest [df_rest.label != 'E']\n",
    "df_rest= df_rest [df_rest.label != 'C']\n",
    "df_rest= df_rest [df_rest.label != 'D']\n",
    "\n",
    "df_i_n = resample(df_i, replace=True, n_samples=1500,random_state = 72)\n",
    "df_g_n = resample(df_g, replace=True, n_samples=1500,random_state = 72)\n",
    "df_c_n = resample(df_c, replace=True, n_samples=1500,random_state = 72)\n",
    "df_e_n = resample(df_e, replace=True, n_samples=1500,random_state = 72)\n",
    "df_d_n = resample(df_d, replace=True, n_samples=1500,random_state = 72)\n",
    "\n",
    "train_data = pd.concat([df_i_n,df_g_n,df_e_n,df_c_n,df_d_n,df_rest])\n",
    "\n",
    "class_counts = train_data.groupby('label').size()\n",
    "\n",
    "# data distribution histogram\n",
    "\n",
    "LABELS = [\"A\", \"B\", \"C\", \"D\", \"E\", \"F\", \"I\", \"J\", \"K\", \"L\", \"M\"]\n",
    "plt.xlabel('title of the xlabel' , color = 'black', fontsize='16', horizontalalignment='center')\n",
    "plt.xticks(color='black', rotation='vertical', fontsize='11', horizontalalignment='right')\n",
    "class_counts.plot.bar(x = train_data.label, align='center', color=(0.1, 0.2, 0.9, 0.9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Shuffle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_data.sample(frac=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove the mixed class (called class A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=train_data[train_data.label!=\"A\"]\n",
    "test_data=test_data[test_data.label!=\"A\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert texts into sequence of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_WORDS=20000\n",
    "tokenizer = Tokenizer(num_words=NUM_WORDS,lower=True)\n",
    "tokenizer.fit_on_texts(train_data.CR_s)\n",
    "sequences_train = tokenizer.texts_to_sequences(train_data.CR_s)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save tokenizer for later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### encode labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "functions=train_data.label.unique()\n",
    "dic={}\n",
    "for i,func in enumerate(functions):\n",
    "    dic[func]=i\n",
    "labels=train_data.label.apply(lambda x:dic[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.loc[train_data['label'] == 'B', 'LABEL'] = 0\n",
    "train_data.loc[train_data['label'] == 'C', 'LABEL'] = 1\n",
    "train_data.loc[train_data['label'] == 'D', 'LABEL'] = 2\n",
    "train_data.loc[train_data['label'] == 'E', 'LABEL'] = 3\n",
    "train_data.loc[train_data['label'] == 'F', 'LABEL'] = 4\n",
    "train_data.loc[train_data['label'] == 'G', 'LABEL'] = 5\n",
    "train_data.loc[train_data['label'] == 'I', 'LABEL'] = 6\n",
    "train_data.loc[train_data['label'] == 'J', 'LABEL'] = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### pad sequences to the same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pad_sequences(sequences_train)\n",
    "y_train = to_categorical(train_data['LABEL'], num_classes=8)\n",
    "print('Shape of X train tensor:', X_train.shape)\n",
    "print('Shape of label train tensor:', y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare  embedding matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed=word2vec_CRs\n",
    "pretrained_weights = embed.wv.syn0\n",
    "vocab_size, emdedding_size = pretrained_weights.shape\n",
    "MAX_NB_WORDS = len(tokenizer.word_index) + 1\n",
    "MAX_SEQUENCE_LENGTH = X_train.shape[1] \n",
    "\n",
    "#####\n",
    "\n",
    "EMBEDDING_DIM = emdedding_size\n",
    "nb_words = MAX_NB_WORDS\n",
    "# we initialize the matrix with random numbers\n",
    "ft_matrix = (np.random.rand(nb_words, EMBEDDING_DIM) - 0.5) / 5.0\n",
    "for word, i in word_index.items():\n",
    "    if i >= MAX_NB_WORDS:\n",
    "        continue\n",
    "    try:\n",
    "        embedding_vector = embed.wv[word]\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        ft_matrix[i] = embedding_vector\n",
    "    except:\n",
    "        pass        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build GRU model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "max_features = len(tokenizer.word_index) + 1\n",
    "input_dim = X_train.shape[1]  # Number of features\n",
    "inputs = Input(name='inputs',shape=[input_dim])\n",
    "layer = Embedding(input_dim=max_features, \n",
    "                            output_dim=EMBEDDING_DIM, \n",
    "                            weights=[ft_matrix],\n",
    "                            trainable=False)(inputs)\n",
    "gru_out = GRU(100,dropout=0.2,recurrent_dropout=0.2, return_sequences=True)(layer)\n",
    "gru_out = Dropout(0.5)(gru_out)\n",
    "output = Dense(len(functions), activation='softmax')(gru_out)\n",
    "model = Model(input=[inputs], output=output)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set weights for classes to resolve the imbalanced input (used if we did not do the upsampling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.utils import class_weight\n",
    "#class_weights = class_weight.compute_class_weight('balanced',\n",
    "  #                                               np.unique(train_data.label),\n",
    "   #                                              train_data.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(X_train, y_train,\n",
    "                    validation_split=0.1,\n",
    "                    epochs=15, \n",
    "                    batch_size=16,\n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)], \n",
    "                    shuffle=True,\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "********\n",
    "# Model Evaluation\n",
    "******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training accurancy vs validation accurancy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Training loss vs validation loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8));\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******\n",
    "# Testing the model on unseen CRs\n",
    "*******"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('tokenizer.pickle', 'rb') as handle:\n",
    "    loaded_tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.loc[test_data['label'] == 'B', 'LABEL'] = 0\n",
    "test_data.loc[test_data['label'] == 'C', 'LABEL'] = 1\n",
    "test_data.loc[test_data['label'] == 'D', 'LABEL'] = 2\n",
    "test_data.loc[test_data['label'] == 'E', 'LABEL'] = 3\n",
    "test_data.loc[test_data['label'] == 'F', 'LABEL'] = 4\n",
    "test_data.loc[test_data['label'] == 'G', 'LABEL'] = 5\n",
    "test_data.loc[test_data['label'] == 'I', 'LABEL'] = 6\n",
    "test_data.loc[test_data['label'] == 'J', 'LABEL'] = 7\n",
    "######\n",
    "\n",
    "sequences_test=loaded_tokenizer.texts_to_sequences(test_data.CR_s)\n",
    "X_test = pad_sequences(sequences_test,maxlen=X_train.shape[1])\n",
    "y_test = to_categorical(test_data['LABEL'], num_classes=8)\n",
    "print('Shape of X train and X test tensor:', X_test.shape)\n",
    "print('Shape of label train and test tensor:', y_test.shape)\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the weights\n",
    "model.save_weights('model_weights.h5')\n",
    "\n",
    "# Save the model architecture\n",
    "with open('model_architecture.json', 'w') as f:\n",
    "    f.write(model.to_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "\n",
    "# Model reconstruction from JSON file\n",
    "with open('model_GRU_architecture.json', 'r') as f:\n",
    "    loaded_model = model_from_json(f.read())\n",
    "\n",
    "# Load weights into the new model\n",
    "loaded_model.load_weights('model_GRU_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate loaded model on test data\n",
    "loaded_model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "score = loaded_model.evaluate(X_test, y_test, verbose=0)\n",
    "print(\"%s: %.2f%%\" % (loaded_model.metrics_names[1], score[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
